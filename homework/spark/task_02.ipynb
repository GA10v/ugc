{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import FloatType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight(helpful_yes, helpful_no):\n",
    "    return helpful_yes / (helpful_yes + helpful_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Yandex_pr').master(\n",
    "    'spark://spark-master:7077').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = spark.read.csv(\n",
    "    '/user-data/combined/products.csv', header=True, inferSchema=True)\n",
    "\n",
    "df_products = df_products.withColumn(\n",
    "    'rating', df_products['rating'].cast(FloatType()))\n",
    "df_products = df_products.withColumn(\n",
    "    'rating_count', df_products['rating_count'].cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = spark.read.csv(\n",
    "    '/user-data/combined/reviews.csv', header=True, inferSchema=True)\n",
    "\n",
    "df_reviews = df_reviews.withColumn(\n",
    "    'helpful_yes', df_reviews['helpful_yes'].cast(FloatType()))\n",
    "df_reviews = df_reviews.withColumn(\n",
    "    'helpful_no', df_reviews['helpful_no'].cast(FloatType()))\n",
    "df_reviews = df_reviews.withColumn(\n",
    "    'stars', df_reviews['stars'].cast(IntegerType()))\n",
    "\n",
    "df_reviews = df_reviews.filter(df_reviews['helpful_yes'] > 0) \\\n",
    "    .filter(df_reviews['helpful_no'] > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_reviews = df_reviews.rdd.filter(lambda line: type(line[4]) is int) \\\n",
    "    .map(lambda line: (line[1], int(line[4]) * calculate_weight(line[6], line[7]))) \\\n",
    "    .map(lambda line: (line[0], (line[1], 1))) \\\n",
    "    .reduceByKey(lambda val1, val2: (val1[0] + val2[0], val1[1] + val2[1])) \\\n",
    "    .mapValues(lambda x: x[0] / x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = spark.createDataFrame(\n",
    "    rdd_reviews, schema=['_key', 'rating_by_reviews'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_products.join(df_reviews, df_products.key == df_reviews._key)\n",
    "df_join = df_join.drop('_key')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.write.csv('/user-data/combined/new_products.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
